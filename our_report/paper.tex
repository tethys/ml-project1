\documentclass{article} % For LaTeX2e
% We will use NIPS submission format
\usepackage{nips13submit_e,times}
% for hyperlinks
\usepackage{hyperref}
\usepackage{url}
% For figures
\usepackage{graphicx} 
% math packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsopn}
\usepackage{ifthen}
\usepackage{natbib}
\usepackage{caption}
\usepackage{subcaption}

\title{Project-I by Group Rome}

\author{
Viviana Petrescu\\
EPFL \\
\texttt{vpetresc@epfl.ch} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\nipsfinalcopy 

\begin{document}

\maketitle

\begin{abstract}
We present our on two tasks, classification and regression on data that is not known. We process the data, investigate baseline methods and present our results here.
For the regression task, out best model was <> and for classification was <>.
\end{abstract}

\section{Regression}
\subsection{Data Description}
The training data $Xtrain$ contains 1400 observations, each 43 dimensional. One training sample has 36 real valued features and 7 categorical features. Our task is to predict the values for unseen test data, consisting in 600 samples. We measure the accuracy of our estimation using $RMSE$. 

\subsection{Data visualization and cleaning}
Initially, our data was not centered, as seen in $Fig.$ \ref{fig:dist_regression}.
We changed the categorical features into dummy variables, leading to a new vector of size 56. $Xtrain$ was then normalized to have 0 mean and standard deviation 1. We applied the same operations to the test data $Xtest$ on which we will report the results.

 We plotted the correlation of every feature with respect to the output $ytrain$ and the scatter plots did not look random. We concluded the features explain the output, but we could not tell if one of them is insignificant.

The predicted values were real values in $[1000,7000]$ and seemed to be grouped into two blobs. We believed initially the smaller blob represented outliers, but since it contained almost $10\%$ of the data we decided not to ignore it.

After looking at every feature individually, we noticed that feature 36 offers a clear separation of the two blobs (see $Fig.$ \ref{fig:feature36}). We therefore chose to fit two models, one in which feature 36 has values $>1.4$ (after normalization) and one in which it is smaller, corresponding to smaller predicted values. 


\begin{figure}[h]
  \begin{subfigure}[b]{0.5\textwidth}
   \includegraphics[width=\textwidth]{figures/dist_regression.png}
    \caption{Mean and standard deviation for the first 36 real\newline valued variables of Xtrain. The input is not norma-\newline lised and feature 36 is the only negative one.}
    \label{fig:dist_regression}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{figures/feature36.png}
    \caption{Feature 36 versus output values. X = 1.4 (black line) and y = 4900 (red line)  provide a good separation of the two blobs.}
    \label{fig:feature36}
  \end{subfigure}
  \caption{• Data visualization. }
\end{figure}

We visually observed some linear correlations between certain features such as feature 2 and 24, 13 and 16, 17 and 20, but we decided to keep them since we did not have time to experiment with their removal or to test their signifcance. This is corroborated by the fact that $Xtrain$ is rank deficient, it has 57 columns after the use of dummy variables but rank 50.

If the input is normally distributed with mean 0 and std 1, then
 $99.99\%$ of them appear between the values -3.891 and 3.891. We therefore remove any points that are outside this interval, considering them outliers.

\subsection{Ridge regression Baseline methods}
 We experimented with least squares using the normal equations, the least squares using gradient descent with alpha.  In both cases we obtained the same result. TODO talk about ill conditioned matriices.
 We report here our best results and parameters for every model. 
 For finding lambda we used 5 fold cross validation. We can see in figure [] the best results for this.
 The matrix was ill conditioned meaning some of the features were correlated, as expected also from our visualization. As Expected leastSquares gave NaN. We observed ridge regression did not improve much, we used a very small lambda. However, when we used polynomial features of degree 3,  with the same lambda and alpha, we obtained a significant improvement.
 
 Remove outliers for every feature. Plot the features also for the other regression


\subsection{Feature transformations}
We tried polynomial and exponential transformations of the features.
For both blobs, we noticed this improved significantly the error on both the training and the validation set.
Using 5-fold cross validation with $\lambda = 1e-5, \alpha = 0.1$ we
noticed for the first blob we could use a polynomial of degree 3. For the second blob, using  $\lambda = 0.001, \alpha = 0.1$ we obtain a best fit for a polynomial of degree 2.
In figure you see a plot of the mean training and validation error.

We increased lambda to prevent overfitting, since we have 10 times less samples for the second blob. However, we still noticed that our RMSE for the validation set  was  bigger for the second blob. This might be due to the fact that we have a very small set for both training and testing of the second model.


\section{Classification}
\subsection{Data description}
We have a two-class classification problem. The training data $Xtrain$ contains 1500 observations, each 32 dimensional. One training sample has 31 real valued features and 1 categorical feature, the 14th feature. Our task is to predict the category for unseen test data, consisting in 1500 samples. We measure the accuracy of our estimation using $RMSE$, $0-1 loss$ and $log-loss$. 

\subsection{Data visualization and cleaning}
We noticed that the samples were not equally distributed among classes, about $35\%$ of the samples were coming from one class and $65\%$ from the other. We changed the labeling from -1/1 to 0/1. 

The training data was again not centered as seen from $Fig.$\ref{fig:dist_classification}
We noticed more outliers in the data of classification than in the one from regression. After removing the outliers and changing feature 14 to a dummy variable we normalized the data to have 0 mean and std 1.
{%%#figures/distribution_classification.png}
\begin{figure}[h]
  \begin{subfigure}[b]{0.7\textwidth}
   \includegraphics[width=\textwidth]{figures/ClassificationDistr.pdf}
    \caption{Mean and standard deviation for the training data features. The input is not norma-\newline lised and contains outliers.}
    \label{fig:dist_classification}
  \end{subfigure}
  \caption{• Data visualization. }
\end{figure}

\subsection{Logistic regression}
\subsection{Feature transformation}

\section{Summary}
In this report, we analyzed a regression dataset and found that ridge regression is a reasonable fit. We estimate that the average test error is 1.213 ($\pm$ 0.02). We tried some feature transformation and found that there is a small improvement giving us a test error of around 1.198 ($\pm$ 0.015). This improvement, however, is not significant.


\subsubsection*{Acknowledgments}
We would like to thank Timur for making the dataset for this study, Carlos and Ilija to help conduct the experiments, and all the students who attended the session making it exciting for us. All the code, as well as this report, was written by Emti. 

\subsubsection*{References}

\end{document}
