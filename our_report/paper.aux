\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Regression}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Data Description}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Data visualization and cleaning}{1}{subsection.1.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:dist_regression}{{1a}{2}{Mean and standard deviation for the first 36 real valued variables of Xtrain. The input is not normalised and feature 36 is the only negative one.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:dist_regression}{{a}{2}{Mean and standard deviation for the first 36 real valued variables of Xtrain. The input is not normalised and feature 36 is the only negative one.\relax }{figure.caption.1}{}}
\newlabel{fig:feature36}{{1b}{2}{Feature 36 versus output values. X = 1.4 (black line) and y = 4900 (red line) provide a good separation of the two blobs.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:feature36}{{b}{2}{Feature 36 versus output values. X = 1.4 (black line) and y = 4900 (red line) provide a good separation of the two blobs.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces • Data visualization. \relax }}{2}{figure.caption.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Ridge regression Baseline methods}{2}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Feature transformations}{2}{subsection.1.4}}
\newlabel{table:feat_transform}{{1.4}{2}{Feature transformations}{figure.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Estimated Train and Test RMSE for the two blob models.\relax }}{2}{table.1}}
\citation{•2013introduction}
\newlabel{fig:degree_blob1}{{2a}{3}{First Blob. Mean RMSE for training set \newline (blue curve) and testing (red curve) versus poly-\newline nomial degree. The errors were computed using\newline 5-fold cross-validation.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:degree_blob1}{{a}{3}{First Blob. Mean RMSE for training set \newline (blue curve) and testing (red curve) versus poly-\newline nomial degree. The errors were computed using\newline 5-fold cross-validation.\relax }{figure.caption.2}{}}
\newlabel{fig:degre_blob2}{{2b}{3}{Second Blob. Mean RMSE for training set (blue curve) and testing (red curve) versus polynomial degree. The errors were computed using 5-fold cross-validation.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:degre_blob2}{{b}{3}{Second Blob. Mean RMSE for training set (blue curve) and testing (red curve) versus polynomial degree. The errors were computed using 5-fold cross-validation.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces • Selection of polynomial degree\relax }}{3}{figure.caption.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Summary}{3}{subsection.1.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Classification}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data description}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Data visualization and cleaning}{4}{subsection.2.2}}
\newlabel{fig:dist_classification}{{3a}{4}{Mean and standard deviation for the training data features. The input is not normalised and contains outliers.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:dist_classification}{{a}{4}{Mean and standard deviation for the training data features. The input is not normalised and contains outliers.\relax }{figure.caption.3}{}}
\newlabel{fig:Lambda_pLr}{{3b}{4}{Train and test error assessment with penalty factor ($\lambda $) for penalized logistic regression for 50-50 split.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:Lambda_pLr}{{b}{4}{Train and test error assessment with penalty factor ($\lambda $) for penalized logistic regression for 50-50 split.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Logistic Regression}{4}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison of logistic regression and penalized logistic regression based on validation accuracy\relax }}{5}{figure.4}}
\newlabel{fig:comp_LR_pLR}{{4}{5}{Comparison of logistic regression and penalized logistic regression based on validation accuracy\relax }{figure.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Best predicted error estimates for the test data\relax }}{5}{table.2}}
\newlabel{table:test_errors}{{2}{5}{Best predicted error estimates for the test data\relax }{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Feature transformation}{5}{subsection.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Summary}{5}{subsection.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Summary}{5}{section.3}}
